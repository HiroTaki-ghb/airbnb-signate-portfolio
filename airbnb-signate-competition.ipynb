{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ea48eb-4faa-4738-b068-ef9a8abd5b9f",
   "metadata": {},
   "source": [
    "# Airbnb price prediction modeling competition hosted by SIGNATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d14a6-8c1b-4e27-8390-0988ea19ac42",
   "metadata": {},
   "source": [
    "* The competition is already terminated and is no longer accessible on the site\n",
    "* The submission with the following code was ranked 8th / 931 participants with RMSE around 140.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90877583-42a7-4dd6-8e86-9714bb9f6ec3",
   "metadata": {},
   "source": [
    "### 1. Preparation : word extraction for the scoring of natural language columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fdff4-951f-4f66-bf4b-cba616183af5",
   "metadata": {},
   "source": [
    "##### 1-1. Extract words from the description column and the name column, and assign the median value to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749743a-afd8-462b-9627-68fa4c60c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== Import necessary libraries==================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import optuna.integration.lightgbm as lgb_tune\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26af6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Extract words from description/name columns ==================\n",
    "\n",
    "df=pd.read_csv('train.csv', index_col=0)\n",
    "\n",
    "# Create a new column 'descname' by concatenating 'description' and 'name' columns with a space separator\n",
    "df['descname'] = df['description'] + ' ' + df['name']\n",
    "df['descname'] = df['descname'].str.lower()  # 小文字化\n",
    "\n",
    "# Initialize CountVectorizer to convert text to a binary matrix representation\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True)\n",
    "X = vectorizer.fit_transform(df['descname'])  \n",
    "\n",
    "# Calculate the total count of each unique word across all documents\n",
    "word_list = vectorizer.get_feature_names_out()\n",
    "word_counts = np.asarray(X.sum(axis=0)).flatten()\n",
    "\n",
    "# Set the column y as a target variable\n",
    "y_values = df['y'].values\n",
    "\n",
    "# Compute median price for each word\n",
    "median_prices = []\n",
    "for i in range(len(word_list)):\n",
    "    doc_indices = X[:, i].nonzero()[0]  \n",
    "    if len(doc_indices) > 0:\n",
    "        median_price = np.median(y_values[doc_indices])\n",
    "    else:\n",
    "        median_price = np.nan\n",
    "    median_prices.append(median_price)\n",
    "\n",
    "# Store the words in a dataframe\n",
    "word_frequency = pd.DataFrame({\n",
    "    'word': word_list,\n",
    "    'count': word_counts,\n",
    "    'y_median': median_prices})    #DataFrame化\n",
    "\n",
    "# Filter the words by the count > 10\n",
    "word_frequency_filtered = word_frequency[word_frequency['count'] >= 10].sort_values(by='y_median', ascending=False)\n",
    "\n",
    "# Score the words by subtracting the median value of all properties from each y_median\n",
    "overall_median = np.median(y_values)\n",
    "word_frequency_filtered['score'] = word_frequency_filtered['y_median'] - overall_median\n",
    "\n",
    "# Export the DataFrame to .csv\n",
    "word_frequency_filtered.to_csv('word_score.csv')　\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418dd91d-fd59-4bef-8e6b-796e3f7c026e",
   "metadata": {},
   "source": [
    "##### 1-2. Decompose amenity column strings into words\n",
    "* *After exporting the dataframe, I gave a point to each amenity item manually on a scale of 0 to 4 by how luxurious the facility I thought it would imply.*<br>\n",
    "* *However, if it is too cumbersome, it is also possible to use the median value by item, with the same method as the description/name columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367a833-7d23-4790-8ce7-016aa93e9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a default dictionary to count the occurrence of each amenity\n",
    "dic = defaultdict(int)\n",
    "\n",
    "# Split the string by commas and count each amenity\n",
    "for _, row in df.iterrows():\n",
    "    match = re.search(r'\\{(.*?)\\}', row['amenities'])\n",
    "    if match:\n",
    "        keys = [k.strip() for k in match.group(1).split(',')]\n",
    "        for key in keys:\n",
    "            dic[key] += 1\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "amenities_df = pd.DataFrame(list(dic.items()), columns=['amenity', 'count'])\n",
    "\n",
    "# Clean up the strings and export it to .csv\n",
    "amenities_df['amenity' ] = amenities_df['amenity'].str.replace('\"', '').str.strip()\n",
    "amenities_df.to_csv('amenity_score.csv')\n",
    "\n",
    "'''\n",
    "【Note】As a result of the above processing, there are 130 amenity elements found.\n",
    "With only 130 elements, I thought it is better to manually assign scores rather than linking them to the median in terms of the accuracy.\n",
    "Therefore, I've manually adopted a 5-point scale from 0 to 4 to each amenity on the above csv.\n",
    "(Elements likely to be highly correlated with high-priced properties were assigned 4 points, \n",
    "while those likely to be with low correlation received lower points.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76238d5-9a2f-4cbc-a5dd-3bba35ee64cd",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessinng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be85d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files\n",
    "df=pd.read_csv('train.csv', index_col=0)\n",
    "amenity_scores_df = pd.read_csv('amenity_score.csv')\n",
    "word_scores_df = pd.read_csv('word_score.csv')\n",
    "\n",
    "# Convert scoring csv files to dictionaries\n",
    "amenity_scores_dict = pd.Series(amenity_scores_df.score.values, index=amenity_scores_df.amenity).to_dict()\n",
    "word_scores_dict = pd.Series(word_scores_df.score.values, index=word_scores_df.word).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea3777-6fb9-44b9-9ff2-53231313afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre(df):\n",
    "  \n",
    "  # ====== Missing values imputation ======\n",
    "\n",
    "  # Fill missing values in bathroom/bedroom/bed columns by median value grouped by df['accommodates']\n",
    "  for column in ['bathrooms', 'bedrooms', 'beds']:\n",
    "      if df[column].isnull().sum() > 0:\n",
    "          medians = df.groupby('accommodates')[column].median()\n",
    "\n",
    "          df[column] = df.apply(\n",
    "              lambda row: medians[row['accommodates']] if pd.isnull(row[column]) else row[column], axis=1\n",
    "          )\n",
    "  # Fill missing rating with overall median\n",
    "  df['review_scores_rating'] = df['review_scores_rating'].fillna(df['review_scores_rating'].median())\n",
    "\n",
    "  # Fill missing categorical host data with 'f' (false)\n",
    "  df['host_identity_verified'] = df['host_identity_verified'].fillna('f')\n",
    "  df[\"host_has_profile_pic\"] = df[\"host_has_profile_pic\"].fillna('f')\n",
    "\n",
    "  # Clean and fill missing 'host_response_rate'\n",
    "  df[\"host_response_rate\"] = df[\"host_response_rate\"].str.rstrip('%').astype('float')\n",
    "  df['host_response_rate'] = df['host_response_rate'].fillna(df['host_response_rate'].median())\n",
    "  \n",
    "  # Convert availability of thumbnail URL into binary (1 if exists, 0 otherwise)\n",
    "  df['thumbnail_url'] = df['thumbnail_url'].notna().astype(int)\n",
    "\n",
    "\n",
    "  # ====== Handle datetime columns ======\n",
    "\n",
    "  # Convert 'host_since' to datetime and fill missing with median\n",
    "  df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "  df['host_since']=df['host_since'].fillna(df['host_since'].median())\n",
    "\n",
    "  # Convert 'first_review' and 'last_review' to datetime\n",
    "  df[\"first_review\"] = pd.to_datetime(df[\"first_review\"])\n",
    "  df['first_review']=df['first_review'].fillna(df['host_since'])\n",
    "\n",
    "  df[\"last_review\"] = pd.to_datetime(df[\"last_review\"])\n",
    "  df['last_review']=df['last_review'].fillna(df['host_since'])\n",
    "\n",
    "  # Convert datetime to numeric values (days or UNIX timestamp)\n",
    "  df['host_days_since'] = (pd.Timestamp('2017-10-05') - df['host_since']).dt.days\n",
    "  df[\"first_review\"] = df[\"first_review\"].astype('int64') // 10**9\n",
    "  df[\"last_review\"] = df[\"last_review\"].astype('int64') // 10**9\n",
    "\n",
    "\n",
    "  # ====== Feature engineering ======\n",
    "\n",
    "  # Clean the amenities string\n",
    "  df['cleaned_amenities'] = df['amenities'].str.replace('\"', '', regex=False)\n",
    "\n",
    "  # Calculate the amenity score from predefined dictionary\n",
    "  def calculate_amenity_score(cleaned_amenities):\n",
    "      total_score = 0\n",
    "      keys = re.findall(r'\\{(.*)\\}', cleaned_amenities)\n",
    "      if keys:\n",
    "          for key in keys[0].split(\",\"):\n",
    "              key = key.strip()\n",
    "              total_score += amenity_scores_dict.get(key, 0)\n",
    "      return total_score\n",
    "  \n",
    "  df['amenity_scores'] = df['cleaned_amenities'].apply(calculate_amenity_score)\n",
    "\n",
    "  # Calculate the name score from predefined dictionary\n",
    "  def calculate_name_score(name):\n",
    "      total_score = 0\n",
    "      words = name.split() \n",
    "      for word in words:\n",
    "          word = word.strip().lower()  \n",
    "          if word in word_scores_dict:\n",
    "              total_score += word_scores_dict[word] \n",
    "      return total_score\n",
    "  df['name_scores'] = df['name'].apply(calculate_name_score)\n",
    "\n",
    "  # Calculate the description score from predefined dictionary\n",
    "  def calculate_description_score(description):\n",
    "      total_score = 0\n",
    "      words = description.split()\n",
    "      for word in words:\n",
    "          word = word.strip().lower()\n",
    "          if word in word_scores_dict:\n",
    "              total_score += word_scores_dict[word]\n",
    "      return total_score\n",
    "  df['description_scores'] = df['description'].apply(calculate_description_score)\n",
    "\n",
    "  # Count number of words in the 'description' field\n",
    "  df[\"description_wordcount\"] = df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "\n",
    " # ====== Drop unused columns ======\n",
    "\n",
    "  drop_list=[\"amenities\",\"city\",\"description\",\"neighbourhood\",\"name\",'cleaned_amenities',\"host_since\",\"zipcode\"]\n",
    "  df=df.drop(drop_list,axis=1)\n",
    "\n",
    "\n",
    "  # Convert object-type columns to category dtype\n",
    "  object_cols = df.select_dtypes(include='object').columns\n",
    "  df[object_cols] = df[object_cols].astype('category')\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2047de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function\n",
    "df=data_pre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ec327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Target Encoding ==================\n",
    "\n",
    "# Define a function for target encoding\n",
    "def apply_target_encoding(train_df, test_df, target_col):\n",
    "    categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    encoding_maps = {}\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        # Computing the average y value by category\n",
    "        mean_map = train_df.groupby(col)[target_col].mean().to_dict()\n",
    "        mean_map['Other'] = global_mean\n",
    "        encoding_maps[col] = mean_map\n",
    "\n",
    "        # Replace unseen categories in the test data with 'Other'\n",
    "        test_df[col] = np.where(test_df[col].isin(mean_map), test_df[col], 'Other')\n",
    "\n",
    "        # Add encoded columns\n",
    "        train_df[f'{col}_encoded'] = train_df[col].map(mean_map).astype(float)\n",
    "        test_df[f'{col}_encoded'] = test_df[col].map(mean_map).astype(float)\n",
    "\n",
    "    # Drop the original columns\n",
    "    train_df.drop(columns=categorical_cols, inplace=True)\n",
    "    test_df.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "    return train_df, test_df, encoding_maps\n",
    "\n",
    "# Load the test data and convert it into a dataframe\n",
    "df_test = pd.read_csv('test.csv', index_col=0)\n",
    "df_test = data_pre(df_test)\n",
    "\n",
    "# apply the target encoding function to the train data and the test data\n",
    "df, df_test, encodings = apply_target_encoding(df, df_test, target_col='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc37a4-eace-46de-99b4-96e16e17c59a",
   "metadata": {},
   "source": [
    "### 3. Data Modeling using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7abe1-b3c9-4285-ac1f-e5c18bee8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb_tune\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "df_train, df_val = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Define target and feature columns for training data\n",
    "col = \"y\"\n",
    "train_y = df_train[col]\n",
    "train_x = df_train.drop(col, axis=1)\n",
    "\n",
    "# Define target and feature columns for validation data\n",
    "val_y = df_val[col]\n",
    "val_x = df_val.drop(col, axis=1)\n",
    "\n",
    "# Create LightGBM dataset objects\n",
    "trains = lgb.Dataset(train_x, train_y)\n",
    "valids = lgb.Dataset(val_x, val_y)\n",
    "\n",
    "# Set basic parameters for LightGBM with Optuna tuning\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "# Train the model with Optuna-tuned LightGBM\n",
    "model_tune = lgb_tune.train(\n",
    "    params, trains, valid_sets=[valids],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100),  \n",
    "        lgb.log_evaluation(100)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predict on the validation set and calculate RMSE\n",
    "val_preds = model_tune.predict(val_x)\n",
    "val_rmse = mean_squared_error(val_y, val_preds, squared=False)\n",
    "print(f'Validation RMSE: {val_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ba4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the test dataset\n",
    "df_test=pd.read_csv(\"test.csv\", index_col=0)\n",
    "df_test=data_pre(df_test)\n",
    "\n",
    "# Predict on the test dataset\n",
    "predict = model_tune.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37cb67-46e0-40ed-b175-cc6c15f2fe89",
   "metadata": {},
   "source": [
    "### 4. Postprocessing and export of the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27d06c-99dc-44e3-b2b2-f66830d8dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predicted prices lower than 10 with 10 to handle unrealistic prediction\n",
    "predict = [max(10, pred) for pred in predict]\n",
    "\n",
    "# Assign the adjusted predictions back to the test DataFrame\n",
    "df_test[\"y\"] = predict\n",
    "\n",
    "# Export the predictions as a CSV file without header\n",
    "df_test[\"y\"].to_csv(\"submission.csv\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
